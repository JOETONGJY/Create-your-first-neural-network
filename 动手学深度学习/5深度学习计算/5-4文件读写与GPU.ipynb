{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当运行一个耗时较长的训练过程时， 最佳的做法是定期保存中间结果， 以确保在服务器电源被不小心断掉时，我们不会损失几天的计算结果。 \n",
    "# 因此，现在是时候学习如何加载和存储权重向量和整个模型了。\n",
    "# torch.rand(size) # 均匀分布U(0, 1)\n",
    "# torch.randn(size) # 高斯正太, random normal\n",
    "# torch.normal(mean, std, size)\n",
    "# torch.arange(start, end, step)\n",
    "# torch.FloatTensor([]) 创建一个float32的张量\n",
    "# pytorch 框架名称\n",
    "# torch 顶层python包\n",
    "# torch.nn 神经网络的模块\n",
    "# torch.nn.init 模块下的子模块,用来初始化函数,不可实例化,用来组织代码\n",
    "# torch.Linear 类，需要实例化,用来生成对象\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74ca090f-3348-4e11-b45d-92e33caa66e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(4)\n",
    "torch.save(x, 'x-file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5969babe-9083-46ac-ab5f-10c442a926a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们现在可以将存储在文件中的数据读回内存\n",
    "# 这里解释一下pickle的机制与用法\n",
    "# pickle 是 Python 自带的“序列化（serialization）工具”，用来把 Python 对象转成二进制数据，然后保存到文件或通过网络传输。\n",
    "# python 中的 save(obj, 'file'), 在底层其实就是 pickle.dump(obj, file)\n",
    "# python 中的 load('file'), 在底层就是 pickle.load(file)\n",
    "# 但是问题在于，pickle会执行任意代码, 会导致风险"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de6364e7-986c-42b9-8d39-8ce515ca081a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.load('x-file', weights_only=True)\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0023614-6f5a-4c1d-86b8-c24900ff1ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.zeros(4)\n",
    "torch.save([x, y], 'x-files')\n",
    "x2, y2 = torch.load('x-files', weights_only=False)\n",
    "(x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18aa72e7-ed83-4d24-8725-1016a0e9bc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们甚至可以写入或读取从字符串映射到张量的字典。 当我们要读取或写入模型中的所有权重时，这很方便"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1544b486-e8fb-472f-94d6-679993f2d2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {'x': x, 'y': y} # 字符串映射到tensor\n",
    "torch.save(mydict, 'mydict')\n",
    "mydict2 = torch.load('mydict', weights_only = False)\n",
    "mydict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0e9eacf-643f-495a-b9d2-8c7f65fd509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存单个权重向量（或其他张量）确实有用， 但是如果我们想保存整个模型，并在以后加载它们， 单独保存每个向量则会变得很麻烦\n",
    "# 因此，深度学习框架提供了内置函数来保存和加载整个网络。 需要注意的一个重要细节是，这将保存模型的参数而不是保存整个模型。 \n",
    "# 例如，如果我们有一个3层多层感知机，我们需要单独指定架构。 因为模型本身可以包含任意代码，所以模型本身难以序列化。(!) \n",
    "# 因此，为了恢复模型，我们需要用代码生成架构， 然后从磁盘加载参数。 让我们从熟悉的多层感知机开始尝试一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4cf6d08-c946-41b3-bc9a-77e11bb98466",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP()\n",
    "X = torch.randn(size = (2, 20))\n",
    "Y = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2664e0ca-7dd4-4ece-8fdf-854b8727827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'mlp.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85861def-6c14-44f1-9825-de4f8a2c2e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone = MLP()\n",
    "clone.load_state_dict(torch.load('mlp.params', weights_only=True))\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88b6096f-4e95-4359-9e99-5e9b76d64e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由于两个实例具有相同的模型参数，在输入相同的X时， 两个实例的计算结果应该相同。 让我们来验证一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a986544-146e-4e0f-8f88-4a009c2a9e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "678cdbd1-1c0c-4b85-9198-32893da23252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 24 14:14:52 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 581.42                 Driver Version: 581.42         CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   47C    P0            N/A  /  130W |    6667MiB /   8188MiB |      7%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2804    C+G   D:\\Yuque\\yuque-desktop\\语雀.exe       N/A      |\n",
      "|    0   N/A  N/A            5256    C+G   ...al 2024.3.5\\bin\\pycharm64.exe      N/A      |\n",
      "|    0   N/A  N/A            5612    C+G   ...lpaper_engine\\wallpaper32.exe      N/A      |\n",
      "|    0   N/A  N/A            6372    C+G   ...em32\\ApplicationFrameHost.exe      N/A      |\n",
      "|    0   N/A  N/A            8656    C+G   ...indows\\System32\\ShellHost.exe      N/A      |\n",
      "|    0   N/A  N/A            9732    C+G   ...ffice6\\promecefpluginhost.exe      N/A      |\n",
      "|    0   N/A  N/A           12052    C+G   ...ef.win7x64\\steamwebhelper.exe      N/A      |\n",
      "|    0   N/A  N/A           12720    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A           13480    C+G   ...kyb3d8bbwe\\EdgeGameAssist.exe      N/A      |\n",
      "|    0   N/A  N/A           13904    C+G   ...IA app\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A           14608    C+G   ...al 2024.3.5\\bin\\pycharm64.exe      N/A      |\n",
      "|    0   N/A  N/A           15372    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           15692    C+G   ...IA app\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A           16468    C+G   ...xyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           16748    C+G   D:\\QQMusic\\QQMusic.exe                N/A      |\n",
      "|    0   N/A  N/A           16820    C+G   ...crosoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A           16880    C+G   ..._cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A           16904    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           17200    C+G   ...mba6cd70vzyy\\ArmouryCrate.exe      N/A      |\n",
      "|    0   N/A  N/A           18860    C+G   D:\\Weixin\\Weixin.exe                  N/A      |\n",
      "|    0   N/A  N/A           19388    C+G   ...em_tray\\lghub_system_tray.exe      N/A      |\n",
      "|    0   N/A  N/A           20212    C+G   ...ntrolPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A           22628    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A           24624    C+G   ....0.3595.94\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           25236    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A           25984    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A           30540    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           32344    C+G   ...acted\\runtime\\WeChatAppEx.exe      N/A      |\n",
      "|    0   N/A  N/A           33876    C+G   ....0.3595.94\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           38700    C+G   D:\\Yuque\\yuque-desktop\\语雀.exe       N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f4f8b74-16b6-460b-ae8b-ae40d93d0231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\systemapp\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9e3ddbc-a456-4016-a103-5864ff4f0340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b30810-2dae-484f-b67b-66453a3d120a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (systemapp)",
   "language": "python",
   "name": "systemapp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
